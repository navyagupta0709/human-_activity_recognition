# -*- coding: utf-8 -*-
"""human activity recognition from sensor data .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B5VdaIV5KCYQR2vSdEswDKo7bzx_vy8v

1. IMPORT AND READ CSV FILES
"""

import pandas as pd
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
df = pd.concat([train, test], ignore_index=True)
df

"""2.EXPLORATORY DATA ANALAYSIS(EDA)"""

df.head()

df.tail()

df.shape

df.info()

df.size

"""3.SUMMARAY STATISTICS"""

df.describe()

df.groupby('Activity').mean()

print(df.columns.tolist())

df['Activity'].value_counts()

# Median values per subject
df.groupby('Activity').median()

"""4.Bar Graph"""

import matplotlib.pyplot as plt
import seaborn as sns

activity_counts = df['Activity'].value_counts()
plt.figure(figsize=(8, 4))
plt.bar(activity_counts.index.astype(str), activity_counts.values, color='skyblue')
plt.title("Activity Class Distribution")
plt.xlabel("Activity Label")
plt.ylabel("Count")
plt.show()

"""5.Correlation Heatmap"""

data = {'feature1': [1, 2, 3, 4, 5],
        'feature2': [5, 4, 3, 2, 1],
        'subject': [10, 20, 30, 40, 50]}
df = pd.DataFrame(data)

plt.figure(figsize=(5, 5))

# Calculate correlation matrix for all numerical columns
corr_matrix = df.corr()

# If you only want to correlate specific numerical columns, e.g., excluding 'subject' if it's not numerical
# corr_matrix = df.drop(columns=['subject']).corr()

sns.heatmap(corr_matrix, cmap='coolwarm', linewidths=0.1)
plt.title("Correlation Heatmap of Features")
plt.show()

"""6.COUNTPLOT"""

data = {'Activity': ['Running', 'Cycling', 'Running', 'Walking', 'Cycling'],
        'Other_Column': [1, 2, 3, 4, 5]}
df = pd.DataFrame(data)

plt.figure(figsize=(10, 4))
sns.countplot(x='Activity', data=df) # Corrected line: added data=df
plt.title("Activity Label Distribution")
plt.xlabel("Activity (Encoded)")
plt.ylabel("Count")
plt.show()

"""7. BOXPLOT"""

data = {'Activity': ['Running', 'Cycling', 'Running', 'Walking', 'Cycling'],
        'Other_Column': [1, 2, 3, 4, 5]}
df = pd.DataFrame(data)

plt.figure(figsize=(10, 4))
sns.boxplot(x='Activity', data=df)
plt.title("Activity Label Distribution")
plt.xlabel("Activity (Encoded)")
plt.ylabel("Count")
plt.show()

"""8.VIOLINPLOT"""

data = {'Activity': ['Running', 'Cycling', 'Running', 'Walking', 'Cycling'],
        'Other_Column': [1, 2, 3, 4, 5]}
df = pd.DataFrame(data)

plt.figure(figsize=(10, 4))
sns.violinplot(x='Activity', data=df)
plt.title("Activity Label Distribution")
plt.xlabel("Activity (Encoded)")
plt.ylabel("Count")
plt.show()

import numpy as np
np.unique(df['Activity'], return_counts=True)

"""9.TEST AND TRAIN"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
X = df.drop(columns=['Activity', 'subject'])
y = df['Activity']

#Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

#Output
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Target classes:", y.unique())
print("Sample of y_test:", y_test.head())

"""10.Knn Accuracy"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

print("KNN Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_knn) * 100))

"""11. Naive Bayes Accuracy"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred_nb = nb.predict(X_test)

# Print accuracy in percentage format
print("Naive Bayes Accuracy: {:.2f}%".format(accuracy_score(y_test, y_pred_nb) * 100))

"""12. Decision Tree Accuracy"""

#Train Decision Tree model
dt = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=42)
dt.fit(X_train, y_train)
# Assuming 'accuracy' is a variable holding the accuracy score (e.g., a float between 0 and 1)
accuracy = dt.score(X_test, y_test) # Example: Calculate accuracy using test set
print(f"Decision Tree Accuracy: {accuracy:.2f}%")

"""13. Label Encoder"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
print("Encoded Labels:", y[:10])

"""14. Accuracy graph of Knn,Naive bayes and Decision Tree"""

import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB

# Step 1: Define the models
models = {
    "KNN": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Naive Bayes": GaussianNB()
}

# Step 2: Train and store accuracy
accuracies = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    acc = model.score(X_test, y_test)
    accuracies[name] = acc * 100  # convert to percentage
    print(f"{name} Accuracy: {acc * 100:.2f}%")

# Step 3: Plot all model accuracies in one bar chart
plt.figure(figsize=(8, 5))
plt.bar(accuracies.keys(), accuracies.values(), color=['skyblue', 'lightgreen', 'salmon'])
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy (%)")
plt.ylim(0, 100)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Add value labels on bars
for i, v in enumerate(accuracies.values()):
    plt.text(i, v + 1, f"{v:.2f}%", ha='center', fontweight='bold')

plt.show()